# ğŸ“š Ã‡oklu Sohbet PDF AsistanÄ± / Multi-Session PDF Chat Assistant ğŸ“„

Bu Streamlit uygulamasÄ±, kullanÄ±cÄ±larÄ±n PDF dosyalarÄ± yÃ¼kleyerek bu dosyalarÄ±n iÃ§eriÄŸi hakkÄ±nda sorular sormasÄ±na olanak tanÄ±r. Uygulama, her bir PDF seti iÃ§in ayrÄ± sohbet oturumlarÄ± oluÅŸturur ve yÃ¶netir, bÃ¶ylece kullanÄ±cÄ±lar farklÄ± belgelerle ilgili sohbetlerini ayrÄ± ayrÄ± tutabilirler.

This Streamlit application allows users to upload PDF files and ask questions about their content. The application creates and manages separate chat sessions for each set of PDFs, enabling users to keep their conversations related to different documents separate.

---

## ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e AÃ§Ä±klama

### âœ¨ Ã–zellikler

*   **PDF YÃ¼kleme:** Birden fazla PDF dosyasÄ± yÃ¼klenebilir.
*   **Ä°Ã§erik TabanlÄ± Soru Cevaplama:** YÃ¼klenen PDF'lerin iÃ§eriÄŸine dayalÄ± olarak sorulara yanÄ±t verir.
*   **Ã‡oklu Sohbet OturumlarÄ±:** Her PDF seti veya sorgu iÃ§in ayrÄ± sohbet oturumlarÄ± oluÅŸturulabilir ve yÃ¶netilebilir.
*   **Yerel Embedding Modeli:** Metinleri vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in yerel bir `sentence-transformers` modeli kullanÄ±r (Ã¶rn: `all-MiniLM-L6-v2`). Bu, embedding iÅŸlemi iÃ§in API anahtarÄ± gerektirmez ve verileriniz bu aÅŸamada dÄ±ÅŸarÄ± Ã§Ä±kmaz.
*   **OpenRouter Entegrasyonu:** BÃ¼yÃ¼k Dil Modeli (LLM) yanÄ±tlarÄ± iÃ§in OpenRouter.ai platformu Ã¼zerinden Ã§eÅŸitli (Ã¼cretsiz veya Ã¼cretli) modellere eriÅŸim saÄŸlar.
*   **Sohbet GeÃ§miÅŸi:** Her oturum iÃ§in sohbet geÃ§miÅŸi tutulur.
*   **KÄ±sÄ±tlayÄ±cÄ± Prompting:** LLM'in sadece yÃ¼klenen PDF iÃ§eriÄŸine odaklanmasÄ±nÄ± saÄŸlamak ve dÄ±ÅŸarÄ±dan bilgi kullanmasÄ±nÄ± engellemek iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ prompt ÅŸablonu kullanÄ±lÄ±r.

### ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

1.  **Depoyu KlonlayÄ±n:**
    ```bash
    git clone https://github.com/SENIN-KULLANICI-ADIN/SENIN-REPO-ADIN.git
    cd SENIN-REPO-ADIN
    ```

2.  **Sanal Ortam OluÅŸturun (Ã–nerilir):**
    ```bash
    python -m venv venv
    # Windows iÃ§in:
    venv\Scripts\activate
    # macOS/Linux iÃ§in:
    source venv/bin/activate
    ```

3.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **API AnahtarlarÄ±nÄ± AyarlayÄ±n (Streamlit Secrets):**
    Projenizin ana dizininde `.streamlit` adÄ±nda bir klasÃ¶r oluÅŸturun ve iÃ§ine `secrets.toml` adÄ±nda bir dosya ekleyin.
    ```toml
    # .streamlit/secrets.toml

    OPENROUTER_API_KEY = "sk-or-v1-SENIN_OPENROUTER_API_ANAHTARIN"

    # Ä°steÄŸe baÄŸlÄ±: KullanÄ±lacak LLM ve yerel embedding modellerini deÄŸiÅŸtirmek iÃ§in
    # LLM_MODEL_NAME = "mistralai/mistral-7b-instruct:free"
    # LOCAL_EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
    ```
    **Not:** `SENIN_OPENROUTER_API_ANAHTARIN` kÄ±smÄ±nÄ± kendi OpenRouter API anahtarÄ±nÄ±zla deÄŸiÅŸtirin. OpenRouter.ai sitesinden Ã¼cretsiz bir hesap oluÅŸturup API anahtarÄ± alabilirsiniz.

5.  **UygulamayÄ± Ã‡alÄ±ÅŸtÄ±rÄ±n:**
    ```bash
    streamlit run app.py
    ```
    Uygulama varsayÄ±lan olarak `http://localhost:8501` adresinde aÃ§Ä±lacaktÄ±r.

### ğŸ› ï¸ NasÄ±l Ã‡alÄ±ÅŸÄ±r?

1.  KullanÄ±cÄ± bir veya daha fazla PDF dosyasÄ± yÃ¼kler.
2.  Uygulama, PDF'lerden metinleri Ã§Ä±karÄ±r ve daha kÃ¼Ã§Ã¼k parÃ§alara (chunks) bÃ¶ler.
3.  Yerel bir `sentence-transformers` modeli kullanÄ±larak bu metin parÃ§alarÄ± vektÃ¶rlere (embeddings) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
4.  Bu vektÃ¶rler, hÄ±zlÄ± benzerlik aramasÄ± iÃ§in bir FAISS vektÃ¶r deposunda saklanÄ±r.
5.  KullanÄ±cÄ± bir soru sorduÄŸunda:
    *   Sorunun vektÃ¶rÃ¼ne en yakÄ±n olan metin parÃ§alarÄ± (ilgili baÄŸlam) vektÃ¶r deposundan alÄ±nÄ±r.
    *   Bu baÄŸlam ve kullanÄ±cÄ±nÄ±n sorusu, LLM'i sadece saÄŸlanan bilgiyi kullanmaya yÃ¶nlendiren Ã¶zel bir prompt ÅŸablonu kullanÄ±larak formatlanÄ±r.
    *   FormatlanmÄ±ÅŸ prompt, OpenRouter Ã¼zerinden seÃ§ilen LLM'e gÃ¶nderilir.
    *   LLM'den gelen yanÄ±t kullanÄ±cÄ±ya gÃ¶sterilir.
6.  Her PDF seti iÃ§in (veya baÅŸlatÄ±lan her yeni sohbet iÃ§in) ayrÄ± sohbet oturumlarÄ± tutulur ve yÃ¶netilir.

---

## ğŸ‡¬ğŸ‡§ğŸ‡ºğŸ‡¸ English Description

### âœ¨ Features

*   **PDF Upload:** Allows uploading multiple PDF files.
*   **Content-Based Q&A:** Answers questions based on the content of the uploaded PDFs.
*   **Multi-Session Chat:** Create and manage separate chat sessions for each set of PDFs or queries.
*   **Local Embedding Model:** Uses a local `sentence-transformers` model (e.g., `all-MiniLM-L6-v2`) to convert text into vectors. This does not require an API key for the embedding process, and your data stays local during this step.
*   **OpenRouter Integration:** Accesses various Large Language Models (LLMs) (free or paid) via the OpenRouter.ai platform for generating responses.
*   **Chat History:** Maintains chat history for each session.
*   **Constrained Prompting:** Utilizes a specifically designed prompt template to ensure the LLM focuses solely on the uploaded PDF content and prevents it from using external knowledge.

### ğŸš€ Setup and Running

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/YOUR-USERNAME/YOUR-REPO-NAME.git
    cd YOUR-REPO-NAME
    ```

2.  **Create a Virtual Environment (Recommended):**
    ```bash
    python -m venv venv
    # For Windows:
    venv\Scripts\activate
    # For macOS/Linux:
    source venv/bin/activate
    ```

3.  **Install Required Libraries:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set Up API Keys (Streamlit Secrets):**
    In your project's root directory, create a folder named `.streamlit` and add a file named `secrets.toml` inside it.
    ```toml
    # .streamlit/secrets.toml

    OPENROUTER_API_KEY = "sk-or-v1-YOUR_OPENROUTER_API_KEY"

    # Optional: To change the LLM and local embedding models used
    # LLM_MODEL_NAME = "mistralai/mistral-7b-instruct:free"
    # LOCAL_EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
    ```
    **Note:** Replace `YOUR_OPENROUTER_API_KEY` with your actual OpenRouter API key. You can get a free API key by signing up at OpenRouter.ai.

5.  **Run the Application:**
    ```bash
    streamlit run app.py
    ```
    The application will typically open at `http://localhost:8501`.

### ğŸ› ï¸ How It Works

1.  The user uploads one or more PDF files.
2.  The application extracts text from the PDFs and splits it into smaller chunks.
3.  These text chunks are converted into vector embeddings using a local `sentence-transformers` model.
4.  These vectors are stored in a FAISS vector store for efficient similarity searches.
5.  When the user asks a question:
    *   The text chunks most similar to the question's vector (relevant context) are retrieved from the vector store.
    *   This context and the user's question are formatted using a custom prompt template designed to guide the LLM to use only the provided information.
    *   The formatted prompt is sent to the selected LLM via OpenRouter.
    *   The response from the LLM is displayed to the user.
6.  Separate chat sessions are maintained and managed for each set of PDFs (or each new chat initiated).

---

### âš™ï¸ `requirements.txt` Ä°Ã§eriÄŸi / Content

```txt
streamlit
openai
pypdf
langchain
langchain-huggingface
sentence-transformers
faiss-cpu
tiktoken
torch==2.1.2
torchvision==0.16.2
torchaudio==2.1.2
numpy<2.0
uuid
